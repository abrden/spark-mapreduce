{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014-1 2do Recuperatorio\n",
    "Se tiene un archivo distribuido con información de una red social en la cual cada registro tiene información sobre un usuario y una lista de sus amigos y sus enemigos (user_id,vector_ids_amigos,vector_ids_enemigos). Queremos encontrar al usuario que figura en mas listas de enemigos, para designarlo el enemigo público número uno.\n",
    "(8 pts por programar lo pedido) (5 pts por programar la agregación necesaria) (2 pts indique cuantos procesos reducers usaría)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (user_id,vector_ids_amigos,vector_ids_enemigos)\n",
    "social_net = [\n",
    "    (1, [2, 3], [4, 5, 6]),\n",
    "    (2, [3, 4], [5, 6]),\n",
    "    (3, [2, 1], [7, 6]),\n",
    "    (4, [6, 7, 1], [6]),\n",
    "    (5, [1, 2, 3, 4], [7]),\n",
    "    (6, [7], [1, 2, 3, 4]),\n",
    "    (7, [6], [1, 5, 4, 6])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usuario que figura en mas listas de enemigos\n",
    "socialRDD = sc.parallelize(social_net)\n",
    "socialRDD.flatMap(lambda x: x[2])\\\n",
    "         .map(lambda x: (x, 1))\\\n",
    "         .reduceByKey(lambda a, b: a + b)\\\n",
    "         .reduce(lambda a, b: a if a[1] > b[1] else b)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2016-1 2do Recuperatorio\n",
    "Una red social almacena el contenido de los chats entre sus usuarios en un RDD que tiene registros con el siguiente formato: (chat_id,user_id, nickname, text). Queremos saber cuál es el usuario (user_id) que mas preguntas hace en sus chats, contabilizamos una pregunta por cada caracter “?” que aparezca en el campo text. Programar en Spark un programa que identifique al usuario preguntón. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (chat_id,user_id, nickname, text)\n",
    "chats = [\n",
    "    (1, 1, 'damu', 'Qué es esto?'),\n",
    "    (2, 2, 'martin', 'Un chat!'),\n",
    "    (3, 1, 'damu', 'Ahhh! Y de donde salio? Whatsapp?'),\n",
    "    (4, 2, 'martin', 'Sí! Cómo sabias?'),\n",
    "    (5, 1, 'damu', 'Adivine'),\n",
    "    (6, 3, 'luis', 'Hola!')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usuario mas pregunton\n",
    "chatRDD = sc.parallelize(chats)\n",
    "chatRDD.map(lambda x: (x[1], x[3].count('?')))\\\n",
    "       .reduceByKey(lambda a, b: a + b)\\\n",
    "       .reduce(lambda a, b: a if a[1] > b[1] else b)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2014-1 1er Parcial\n",
    "Se tiene un archivo con información sobre visitas a páginas web de la forma: (URL, visitas, fecha). Existe solo un registro por día para cada URL. Se quiere generar un archivo que, por cada URL, indique cuál fue la fecha en la que tuvo mas visitas y la cantidad de visitas.\n",
    "Programar lo pedido en Map Reduce usando agregación para minimizar la cantidad de datos que deben transferirse en la red.\n",
    "Atención: La resolución es muy simple, trivial, asi que es fundamental resolver la agregación para el puntaje completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (URL, visitas, fecha)\n",
    "visits = [\n",
    "    ('reddit.com',99999, 20160812),\n",
    "    ('reddit.com', 9999999, 20160810),\n",
    "    ('reddit.com', 999999999, 20160809),\n",
    "    ('reddit.com', 99999999999, 20160808),\n",
    "    ('reddit.com/r/argentina', 45000000, 20160812),\n",
    "    ('reddit.com/r/argentina', 450000, 20160810),\n",
    "    ('reddit.com/r/argentina', 4500, 20160809),\n",
    "    ('reddit.com/r/gamedev', 2, 20160812),\n",
    "    ('reddit.com/r/gamedev', 1, 20160810),\n",
    "    ('reddit.com/r/gamedev', 0, 20160809),\n",
    "    ('reddit.com/r/programmerhumor', 1, 20160812)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reddit.com/r/gamedev', (2, 20160812)),\n",
       " ('reddit.com/r/programmerhumor', (1, 20160812)),\n",
       " ('reddit.com/r/argentina', (45000000, 20160812)),\n",
       " ('reddit.com', (99999999999, 20160808))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cuál fue la fecha en la que tuvo mas visitas y la cantidad de visitas\n",
    "visitsRDD = sc.parallelize(visits)\n",
    "visitsRDD.map(lambda x: (x[0], (x[1], x[2])))\\\n",
    "         .reduceByKey(lambda a, b: a if a[0] > b[0] else b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2015-2 2do Recuperatorio\n",
    "Un telescopio registra automaticamente la luminosidad de distintas estrellas generando un RDD con registros de tipo (star_id,magnitude,spectral_type, timestamp). Queremos obtener un listado de estrellas que tienen el mismo tipo espectral e igual promedio de magnitud una vez redondeado el mismo a un decimal. El resultado debe ser una lista en donde cada elemento de la lista es una lista de ids de estrellas similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (star_id,magnitude,spectral_type, timestamp)\n",
    "stars = [\n",
    "    (1, 5, 1, 1),\n",
    "    (2, 10, 1, 1),\n",
    "    (3, 6, 1, 1),\n",
    "    (4, 5.5, 2, 1),\n",
    "    (1, 6, 1, 2),\n",
    "    (2, 9, 1, 2),\n",
    "    (3, 5, 1, 2),\n",
    "    (1, 5.5, 1, 3),\n",
    "    (2, 11, 1, 3),\n",
    "    (3, 5.5, 1, 3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((2, 5.5), [4]), ((1, 10.0), [2]), ((1, 5.5), [1, 3])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listas de ids de estrellas con mismo tipo espectral y promedio de magnitud\n",
    "starsRDD = sc.parallelize(stars)\n",
    "starsRDD.map(lambda x: (x[0], (x[2], x[1], 1)))\\\n",
    "        .reduceByKey(lambda a, b: (a[0], a[1] + b[1], a[2] + b[2]))\\\n",
    "        .map(lambda x: ((x[1][0], round(x[1][1]/x[1][2], 1)) ,[x[0]]))\\\n",
    "        .reduceByKey(lambda a, b: a + b)\\\n",
    "        .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2015-2 1er Parcial\n",
    "Se tiene un RDD con las coordenadas de rectángulos de la forma (x1,x2,y1,y2). Se pide programar en PySpark un programa que encuentre el rectángulo de superficie mínima que contiene al punto (w,z)\n",
    "\n",
    "```\n",
    "y2   -------------\n",
    "    |             |\n",
    "    |             |\n",
    "y1   -------------\n",
    "\n",
    "     x1         x2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (w, z)\n",
    "w = 1\n",
    "z = 1\n",
    "\n",
    "# (x1, x2, y1, y2)\n",
    "rectangles = [\n",
    "    (0, 4, 0, 40),\n",
    "    (0, 4, 0, 4),\n",
    "    (20, 30, 50, 60),\n",
    "    (150, 153, 12, 74)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4, 0, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rectanglesRDD = sc.parallelize(rectangles)\n",
    "rectanglesRDD.filter(lambda x: (x[0] < w < x[1]) and (x[2] < z < x[3]))\\\n",
    "             .map(lambda x: (x, abs(x[1] - x[0]) * abs(x[3] - x[2])))\\\n",
    "             .reduce(lambda a, b: a if a[1] < b[1] else b)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Simil 2016-1 1er Parcial\n",
    "Dado un rdd con registros (Padron, Codigo de Materia, Codigo de Curso, Profesor a Cargo, Nota)\n",
    "Hacer un programa en PySpark que liste para cada curso de cada materia, el promedio de notas de los alumnos que aprobaron la misma. El listado debe contener Codigo de Materia, Codigo de Curso, Profesor a cargo y Promedio de Notas, y debe estar ordenado por materia. Tener en cuenta solo los cursos que tengan al menos 2 alumnos aprobados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (Padron, Codigo de Materia, Codigo de Curso, Profesor a Cargo, Nota)\n",
    "# Sup que el profesor a cargo es fijo segun el codigo de curso\n",
    "alumni = [\n",
    "    (1, 5, 1, 'Rosita', 1),\n",
    "    (2, 6, 2, 'Luis', 2),\n",
    "    (3, 6, 1, 'Diego', 3),\n",
    "    (4, 5, 2, 'Pablo', 4),\n",
    "    (5, 6, 1, 'Diego', 5),\n",
    "    (6, 5, 2, 'Pablo', 6),\n",
    "    (7, 5, 1, 'Rosita', 7),\n",
    "    (3, 5, 2, 'Pablo', 8),\n",
    "    (2, 6, 1, 'Diego', 9),\n",
    "    (1, 5, 2, 'Pablo', 10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 2, 'Pablo', 7), (6, 1, 'Diego', 7)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alumniRDD = sc.parallelize(alumni)\n",
    "# (Mapeamos registros a (cod_materia, cod_curso), (profesor, nota, 1))\n",
    "# Y terminamos con registros (cod_materia, cod_curso, profesor, promedio_notas_aprobados)\n",
    "alumniRDD.map(lambda x: ((x[1], x[2]), (x[3], x[4], 1)))\\\n",
    "         .filter(lambda x: x[1][1] >= 4)\\\n",
    "         .reduceByKey(lambda a, b: (a[0], a[1] + b[1], a[2] + b[2]))\\\n",
    "         .filter(lambda x: x[1][2] >= 2)\\\n",
    "         .map(lambda x: (x[0][0], x[0][1], x[1][0], x[1][1]/x[1][2]))\\\n",
    "         .sortBy(lambda x: x[0])\\\n",
    "         .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Simil Parcial 2014-2 2do Recuperatorio\n",
    " Se tiene un rdd con datos de la forma (url_id,user_id) representando visitas a un website. (Se pueden repetir registros). Se pide programar en PySpark un script que indique cual es el promedio global de sitios visitados por usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (url_id,user_id)\n",
    "visits = [\n",
    "    (2,24),\n",
    "    (2,24),\n",
    "    (3,24),\n",
    "    (3,24),\n",
    "    (3,24),\n",
    "    (4,12),\n",
    "    (1,12),\n",
    "    (1,12),\n",
    "    (3,12),\n",
    "    (5,12)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visitsRDD = sc.parallelize(visits)\n",
    "# what do u meaaaaaaaaaaaAAAAAAAAAAAAAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simil Parcial 2014-2 Recuperatorio\n",
    "Se tiene un rdd con datos de la forma (url_id,user_id) representando visitas a un website. (Se pueden repetir registros). Se pide programar en PySpark un script que devuelva el usuario que mas sitios diferentes visita (no importa cuantas veces visita cada sitio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitsRDD.distinct()\\\n",
    "         .map(lambda x: (x[1], 1))\\\n",
    "         .reduceByKey(lambda a, b: a + b)\\\n",
    "         .reduce(lambda a, b: a if a[1] > b[1] else b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
